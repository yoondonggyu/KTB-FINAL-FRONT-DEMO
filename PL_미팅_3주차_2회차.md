# PL 미팅 정리 - 3주차 2회차

## 기본 정보
| 항목 | 내용 |
|------|------|
| **팀명** | 9팀 (Devths) |
| **미팅 일시** | 2026.01.08 |
| **미팅 회차** | 3주차 2회차 |
| **참여 인원** | estar.yoon(윤동규) |

---

## 1. 이전 PL 미팅 이후 구현 내용 (완료)
> **사실 기반으로 작성, 완료 기준 명확히**

- **구현한 기능:**
  - 서비스 시나리오 문서화 완료
  - API 명세 작성 (AI Server 9개 API 정의)
  - Sequence Diagram 작성
  - VectorDB 설계 문서 작성
  - ADR 문서 정리 (ADR-001 ~ ADR-008)
  
- **관련 PR / 커밋 링크:**
  - (추가 필요)
  
- **구현 범위 요약:**
  - AI 서비스 시나리오 (이력서 분석, 면접, 채팅, 캘린더, 마스킹) 워크플로우 정의
  - API 처리 방식 결정 (동기/비동기/스트리밍)
  - VectorDB Collection 5개 설계 완료

---

## 2. 이전 PL 미팅 이후 추가로 진행한 작업
> **예상에 없었으나 실제로 진행한 작업**

- **추가 작업 내용:**
  - OCR + 임베딩 내부 통합 처리 설계 변경 (ADR-008)
  - 인프라 진화 전략 로드맵 작성 (ADR-006, ADR-007)
  - MLOps 파이프라인 문서 작성
  
- **추가 작업을 하게 된 이유:**
  - 폴링 방식의 성능 이슈 발견 → 내부 통합 처리로 변경
  - PL 피드백 반영 (Kubernetes/Kubeflow 도입 시기 명확화)

---

## 3. 구현하지 못한 내용
> **계획 대비 미완료 항목**

- **미구현 기능:**
  - 클라우드 인프라 상세 설계
  - 모델 성능 지표 정의
  - 실제 코드 구현 (설계 단계)
  
- **구현하지 못한 이유:**
  - 3주차는 설계 주간 → 다음 주에 본격 개발 예정
  - 비용 고려가 필요하여 다음 주로 보류

---

## 4. 현재 어려운 점
> **기술적·구조적 어려움만 작성**

- **기술적 문제:**
  - Kubeflow, Airflow 등 MLOps 도구 선택 기준
  - 성능 지표 어떻게 정의해야 하는지
  
- **구조/설계 관련 고민:**
  - 아키텍처 설계 범위 (인프라까지? LangChain만?)
  - VectorDB 데이터 저장 구조
  - 채팅방 컨텍스트 관리 방식
  
- **스스로 시도해본 해결 방법:**
  - ADR 문서로 의사결정 기록
  - 이전 기수 Wiki 참고 시작

---

## 5. PL의 답변
> **PL 미팅에서 받은 피드백을 수강생이 정리**

### 📌 PL 피드백 요약

| 주제 | 피드백 내용 |
|------|------------|
| **아키텍처 범위** | 3주차는 AI(LangChain) 아키텍처만 그려도 됨 |
| **클라우드 설계** | 다음 주에 비용 고려해서 본격적으로 진행 |
| **성능 지표** | 이전 기수 WIKI 참고 (응답속도, 정확도 등) |
| **VectorDB** | 데이터 저장 방식 고민 필요, 임베딩 모델 활용 |
| **OCR** | Upstage OCR, 클로바 등 검토 |
| **API 서빙** | 서버리스 방식 고려 |
| **비동기 처리** | 폴링은 백엔드에서 처리 |

### 💡 상세 피드백

1. **아키텍처 그림**
   - 서로 관련있는 모듈들도 표시하기
   - 시스템 아키텍처 그림 정리 필요
   - 마지막에 내용 + 그림 모두 정리

2. **평가 지표**
   - 정성적 / 정량적 평가지표 모두 필요
   - 비용도 지표화하기

3. **다중 사용자 고려**
   - 확장성 있게 설계

4. **채팅방 컨텍스트 관리**
   - Redis 활용 고려
   - LangChain에서 세션 하나 정도 인메모리에 채팅 내용 유지
   - AI ↔ Backend 협업 필요
   - **참고 자료:** Redis 공식 문서, Memory Architecture, AI Agent 문서

5. **코드 품질**
   - Pydantic으로 코드 검증

6. **백엔드 연계**
   - ERD 완료 후 스키마 작성
   - Dummy 데이터 준비

---

### ✅ 즉시 반영해야 할 사항

| 우선순위 | 할 일 | 담당 |
|---------|------|------|
| 🔴 높음 | 이전 기수 WIKI에서 성능 지표 확인 | AI |
| 🔴 높음 | 임베딩 모델 선정 (Gemini, OpenAI 비교) | AI |
| 🟡 중간 | VectorDB 저장 구조 상세화 | AI |
| 🟡 중간 | Redis 활용 방안 조사 | AI/Backend |

---

### 📋 추후 개선 또는 보류 사항

| 항목 | 일정 | 비고 |
|------|------|------|
| 클라우드 인프라 설계 | 4주차 | 비용 고려 필요 |
| 서버리스 API 검토 | 4주차 | Lambda, Cloud Functions 등 |
| Upstage/클로바 OCR 비교 | 5주차 | 비용 대비 성능 평가 |

---

### ☑️ 체크리스트

- [x] 실제 구현 기준으로 작성함
- [ ] PR / 커밋 링크 포함함 (추가 필요)
- [x] 미구현 사유를 솔직하게 작성함
- [x] 구두 설명 없이 문서만으로 상황 파악 가능함

---

## 📚 참고 자료

- [이전 기수 WIKI](https://github.com/100-hours-a-week) (성능 지표 참고)
- [Redis 공식 문서](https://redis.io/docs/)
- [LangChain Memory](https://python.langchain.com/docs/modules/memory/)
- [Upstage Document AI](https://www.upstage.ai/)
- [CLOVA OCR](https://clova.ai/ocr)
